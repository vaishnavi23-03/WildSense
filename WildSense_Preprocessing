{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30684,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2024-04-27T15:06:20.602719Z","iopub.execute_input":"2024-04-27T15:06:20.603267Z","iopub.status.idle":"2024-04-27T15:06:20.615139Z","shell.execute_reply.started":"2024-04-27T15:06:20.603236Z","shell.execute_reply":"2024-04-27T15:06:20.614066Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"from datasets import load_dataset\n\ndataset = load_dataset(\"society-ethics/lila_camera_traps\", \"Caltech Camera Traps\")\n","metadata":{"execution":{"iopub.status.busy":"2024-04-27T15:06:22.284866Z","iopub.execute_input":"2024-04-27T15:06:22.285635Z","iopub.status.idle":"2024-04-27T15:07:47.193448Z","shell.execute_reply.started":"2024-04-27T15:06:22.285607Z","shell.execute_reply":"2024-04-27T15:07:47.192634Z"},"trusted":true},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/52.3k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4dfb4383c2124a59a06ff3675d2a8b5d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/35.9k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"104062b890af4decadf715e9363cf40a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/10.2M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4c881e1c2b274644bafbea7405077692"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6f95744e665341c9869962a4f79db69d"}},"metadata":{}}]},{"cell_type":"code","source":"dataset","metadata":{"execution":{"iopub.status.busy":"2024-04-27T15:09:27.915289Z","iopub.execute_input":"2024-04-27T15:09:27.915667Z","iopub.status.idle":"2024-04-27T15:09:27.923013Z","shell.execute_reply.started":"2024-04-27T15:09:27.915640Z","shell.execute_reply":"2024-04-27T15:09:27.922025Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['file_name', 'width', 'height', 'seq_num_frames', 'date_captured', 'seq_id', 'location', 'rights_holder', 'frame_num', 'annotations', 'bboxes', 'image'],\n        num_rows: 243100\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"import cv2\nfrom skimage.feature import local_binary_pattern\nfrom skimage import io\nimport numpy as np\nfrom tqdm import tqdm\nfrom datasets import load_dataset","metadata":{"execution":{"iopub.status.busy":"2024-04-27T15:09:28.918240Z","iopub.execute_input":"2024-04-27T15:09:28.918804Z","iopub.status.idle":"2024-04-27T15:09:29.412854Z","shell.execute_reply.started":"2024-04-27T15:09:28.918774Z","shell.execute_reply":"2024-04-27T15:09:29.412101Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def extract_color_histogram(image):\n    hist = cv2.calcHist([image], [0, 1, 2], None, [8, 8, 8], [0, 256, 0, 256, 0, 256])\n    hist = cv2.normalize(hist, hist).flatten()\n    return hist","metadata":{"execution":{"iopub.status.busy":"2024-04-27T15:09:31.006389Z","iopub.execute_input":"2024-04-27T15:09:31.006992Z","iopub.status.idle":"2024-04-27T15:09:31.013027Z","shell.execute_reply.started":"2024-04-27T15:09:31.006961Z","shell.execute_reply":"2024-04-27T15:09:31.011780Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"col histograms","metadata":{}},{"cell_type":"code","source":"def extract_lbp(image):\n    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n    lbp = local_binary_pattern(gray, 8, 1, method='uniform')\n    (hist, _) = np.histogram(lbp.ravel(), bins=np.arange(0, 64), range=(0, 256))\n    hist = hist.astype(\"float\")\n    hist /= (hist.sum() + 1e-7)\n    return hist\n","metadata":{"execution":{"iopub.status.busy":"2024-04-27T15:09:32.158071Z","iopub.execute_input":"2024-04-27T15:09:32.158699Z","iopub.status.idle":"2024-04-27T15:09:32.164297Z","shell.execute_reply.started":"2024-04-27T15:09:32.158667Z","shell.execute_reply":"2024-04-27T15:09:32.163430Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def extract_edges(image):\n    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n    edges = cv2.Canny(gray, 100, 200)\n    return edges.flatten()","metadata":{"execution":{"iopub.status.busy":"2024-04-27T15:09:33.090115Z","iopub.execute_input":"2024-04-27T15:09:33.090800Z","iopub.status.idle":"2024-04-27T15:09:33.095285Z","shell.execute_reply.started":"2024-04-27T15:09:33.090772Z","shell.execute_reply":"2024-04-27T15:09:33.094403Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def extract_shape_descriptors(image):\n    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n    contours, _ = cv2.findContours(gray, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n    \n    if len(contours) == 0:\n        return [0]  \n    \n    contour_area = [cv2.contourArea(contour) for contour in contours]\n    return contour_area\n","metadata":{"execution":{"iopub.status.busy":"2024-04-27T15:09:33.346183Z","iopub.execute_input":"2024-04-27T15:09:33.346925Z","iopub.status.idle":"2024-04-27T15:09:33.352023Z","shell.execute_reply.started":"2024-04-27T15:09:33.346899Z","shell.execute_reply":"2024-04-27T15:09:33.351097Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"import requests\nimport numpy as np\nfrom tqdm import tqdm\nimport cv2","metadata":{"execution":{"iopub.status.busy":"2024-04-27T15:09:38.338200Z","iopub.execute_input":"2024-04-27T15:09:38.338553Z","iopub.status.idle":"2024-04-27T15:09:38.343170Z","shell.execute_reply.started":"2024-04-27T15:09:38.338526Z","shell.execute_reply":"2024-04-27T15:09:38.342097Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"**taking 1 from 100 values because 231400 is actual dataset**","metadata":{}},{"cell_type":"code","source":"# import requests\n# import numpy as np\n# from tqdm import tqdm\n# import cv2\n# i=0\n\n# all_features = []\n\n# for example in tqdm(dataset[\"train\"]):\n   \n#     try:\n#         # Extract the image URL from the example\n#         image_url = example[\"image\"]\n        \n#         # Download the image from the URL\n#         response = requests.get(image_url)\n        \n#         # Check if the response is successful\n#         if response.status_code == 200:\n#             # Decode the image\n#             image_array = np.frombuffer(response.content, np.uint8)\n#             image = cv2.imdecode(image_array, cv2.IMREAD_COLOR)\n            \n#             # Check if the image decoding was successful\n#             if image is not None:\n#                 # Extract features\n#                 color_hist_features = extract_color_histogram(image)\n#                 lbp_features = extract_lbp(image)\n#                 edge_features = extract_edges(image)\n#                 shape_features = extract_shape_descriptors(image)\n                \n#                 # Combine features\n#                 combined_features = np.concatenate([color_hist_features, lbp_features, edge_features, shape_features])\n#                 all_features.append(combined_features)\n#             else:\n#                 print(\"Error: Unable to decode image.\")\n#         else:\n#             print(f\"Error: Unable to download image - Status Code: {response.status_code}\")\n#     except Exception as e:\n#         print(f\"Error occurred while processing image: {e}\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\n\n# Initialize a list to store labels\nall_labels = []\n\n# Loop through the dataset to collect labels\nfor i, example in enumerate(tqdm(dataset[\"train\"])):\n  \n        try:\n            # Extract the category name from the annotations\n            category_name = example[\"annotations\"][\"taxonomy\"][0][\"species\"]  # Assuming the category name is stored in this structure\n            all_labels.append(category_name)\n        except Exception as e:\n            print(f\"Error occurred while processing image: {e}\")\n\n# Convert the list of labels to a NumPy array\nall_labels = np.array(all_labels)\n\n# Print the labels\nprint(all_labels)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-27T15:09:56.922820Z","iopub.execute_input":"2024-04-27T15:09:56.923238Z","iopub.status.idle":"2024-04-27T15:10:53.253979Z","shell.execute_reply.started":"2024-04-27T15:09:56.923209Z","shell.execute_reply":"2024-04-27T15:10:53.253101Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stderr","text":"100%|██████████| 243100/243100 [00:56<00:00, 4319.32it/s]\n","output_type":"stream"},{"name":"stdout","text":"[None None 2 ... None None 8]\n","output_type":"stream"}]},{"cell_type":"code","source":"non_none_labels = all_labels[all_labels != None]\nprint(non_none_labels)\nprint(len(non_none_labels))","metadata":{"execution":{"iopub.status.busy":"2024-04-27T15:12:55.105393Z","iopub.execute_input":"2024-04-27T15:12:55.105764Z","iopub.status.idle":"2024-04-27T15:12:55.123296Z","shell.execute_reply.started":"2024-04-27T15:12:55.105737Z","shell.execute_reply":"2024-04-27T15:12:55.122329Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"[2 8 5 ... 8 5 8]\n67692\n","output_type":"stream"}]},{"cell_type":"code","source":"# Convert the list of labels to a NumPy array\nall_labels = np.array(all_labels)\n\n# Print the labels\nprint(all_labels)","metadata":{"execution":{"iopub.status.busy":"2024-04-27T15:12:56.976973Z","iopub.execute_input":"2024-04-27T15:12:56.977749Z","iopub.status.idle":"2024-04-27T15:12:56.984272Z","shell.execute_reply.started":"2024-04-27T15:12:56.977719Z","shell.execute_reply":"2024-04-27T15:12:56.983363Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"[None None 2 ... None None 8]\n","output_type":"stream"}]},{"cell_type":"code","source":"import requests\nimport numpy as np\nfrom tqdm import tqdm\nimport cv2\n\n\nsampling_interval = 100\n\nall_features = []\n\nall_labels2=[]\n\nfor i, (example, label) in enumerate(zip(tqdm(dataset[\"train\"]), all_labels)):\n    if (i>121550):\n        break\n    if i % sampling_interval == 0 and label is not None:\n        try:\n           \n            image_url = example[\"image\"]\n\n            \n            response = requests.get(image_url)\n\n           \n            if response.status_code == 200:\n                \n                image_array = np.frombuffer(response.content, np.uint8)\n                image = cv2.imdecode(image_array, cv2.IMREAD_COLOR)\n\n                \n                if image is not None:\n                    \n                    color_hist_features = extract_color_histogram(image)\n                    lbp_features = extract_lbp(image)\n                    edge_features = extract_edges(image)\n                    shape_features = extract_shape_descriptors(image)\n\n                    combined_features = np.concatenate([color_hist_features, lbp_features, edge_features, shape_features])\n                    all_features.append(combined_features)\n                    all_labels2.append(label)\n                else:\n                    print(\"Error: Unable to decode image.\")\n            else:\n                print(f\"Error: Unable to download image - Status Code: {response.status_code}\")\n        except Exception as e:\n            print(f\"Error occurred while processing image: {e}\")\n\n\nall_features = np.array(all_features)\nall_labels = np.array(all_labels)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-27T15:12:59.365300Z","iopub.execute_input":"2024-04-27T15:12:59.365656Z","iopub.status.idle":"2024-04-27T15:19:45.998667Z","shell.execute_reply.started":"2024-04-27T15:12:59.365628Z","shell.execute_reply":"2024-04-27T15:19:45.997340Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stderr","text":" 50%|█████     | 121551/243100 [06:46<06:46, 299.32it/s] \n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[14], line 50\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError occurred while processing image: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# Convert the lists of features and labels to NumPy arrays\u001b[39;00m\n\u001b[0;32m---> 50\u001b[0m all_features \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_features\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m all_labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(all_labels)\n","\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (309,) + inhomogeneous part."],"ename":"ValueError","evalue":"setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (309,) + inhomogeneous part.","output_type":"error"}]},{"cell_type":"code","source":"import pandas as pd\ndf_features = pd.DataFrame(all_features)\ndf_features","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_features","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n","metadata":{},"execution_count":null,"outputs":[]}]}